{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0500e6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0830f656",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe4a9619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the mean imputed data\n",
    "df_train_mean = pd.read_csv(r\"data\\training_mean_imputed.csv\")\n",
    "df_test_mean = pd.read_csv(r\"data\\test_mean_imputed.csv\")\n",
    "\n",
    "# the iterative imputed data\n",
    "df_train_iter = pd.read_csv(r\"data\\training_iter_imputed.csv\")\n",
    "df_test_iter = pd.read_csv(r\"data\\test_iter_imputed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61840c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mean = df_train_mean.drop(columns=\"Potability\")\n",
    "y_train_mean = df_train_mean[\"Potability\"]\n",
    "\n",
    "X_test_mean = df_test_mean.drop(columns=\"Potability\")\n",
    "y_test_mean = df_test_mean[\"Potability\"]\n",
    "\n",
    "X_train_iter = df_train_iter.drop(columns=\"Potability\")\n",
    "y_train_iter = df_train_iter[\"Potability\"]\n",
    "\n",
    "X_test_iter = df_test_iter.drop(columns=\"Potability\")\n",
    "y_test_iter = df_test_iter[\"Potability\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a008df",
   "metadata": {},
   "source": [
    "## Train Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cca8b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1a31745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.6265243902439024\n",
      "Test F1-Score: 0.0\n",
      "Test Precision: 0.0\n",
      "Test Recall: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brusp\\.conda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Train the logistic regression model and use this as baseline for comparison\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_model_mean = LogisticRegression()\n",
    "log_model_mean.fit(X_train_mean, y_train_mean)\n",
    "\n",
    "preds_mean = log_model_mean.predict(X_test_mean)\n",
    "print(f\"Test Acc: {accuracy_score(y_test_mean, preds_mean)}\")\n",
    "print(f\"Test F1-Score: {f1_score(y_test_mean, preds_mean)}\")\n",
    "print(f\"Test Precision: {precision_score(y_test_mean, preds_mean)}\")\n",
    "print(f\"Test Recall: {recall_score(y_test_mean, preds_mean)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94c50f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.6265243902439024\n",
      "Test F1-Score: 0.0\n",
      "Test Precision: 0.0\n",
      "Test Recall: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brusp\\.conda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Train the logistic regression model and use this as baseline for comparison\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_model_iter = LogisticRegression()\n",
    "log_model_iter.fit(X_train_iter, y_train_iter)\n",
    "\n",
    "preds_iter = log_model_iter.predict(X_test_iter)\n",
    "print(f\"Test Acc: {accuracy_score(y_test_iter, preds_iter)}\")\n",
    "print(f\"Test F1-Score: {f1_score(y_test_iter, preds_iter)}\")\n",
    "print(f\"Test Precision: {precision_score(y_test_iter, preds_iter)}\")\n",
    "print(f\"Test Recall: {recall_score(y_test_iter, preds_iter)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db76c5e2",
   "metadata": {},
   "source": [
    "## Train Other Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d3d9dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42b5836e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Nearest Neighbor\": KNeighborsClassifier(),\n",
    "    \"Bagging\": BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=10),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Ada Boost\": AdaBoostClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "391e564e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training Decision Tree...\n",
      "Test F1-Score: 0.46280991735537186\n",
      "Test Precision: 0.4686192468619247\n",
      "Test Recall: 0.45714285714285713\n",
      "\n",
      "\n",
      "\n",
      "Start training SVM...\n",
      "Test F1-Score: 0.4482758620689655\n",
      "Test Precision: 0.7572815533980582\n",
      "Test Recall: 0.3183673469387755\n",
      "\n",
      "\n",
      "\n",
      "Start training Nearest Neighbor...\n",
      "Test F1-Score: 0.474040632054176\n",
      "Test Precision: 0.5303030303030303\n",
      "Test Recall: 0.42857142857142855\n",
      "\n",
      "\n",
      "\n",
      "Start training Bagging...\n",
      "Test F1-Score: 0.4607843137254902\n",
      "Test Precision: 0.5766871165644172\n",
      "Test Recall: 0.3836734693877551\n",
      "\n",
      "\n",
      "\n",
      "Start training Random Forest...\n",
      "Test F1-Score: 0.4684210526315789\n",
      "Test Precision: 0.6592592592592592\n",
      "Test Recall: 0.363265306122449\n",
      "\n",
      "\n",
      "\n",
      "Start training Ada Boost...\n",
      "Test F1-Score: 0.28488372093023256\n",
      "Test Precision: 0.494949494949495\n",
      "Test Recall: 0.2\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_dict = {}\n",
    "for model_name, model in dict_models.items():\n",
    "    print(f\"Start training {model_name}...\")\n",
    "    model.fit(X_train_mean, y_train_mean)\n",
    "    \n",
    "    preds = model.predict(X_test_mean)\n",
    "    f1 = f1_score(y_test_mean, preds)\n",
    "    precision = precision_score(y_test_mean, preds)\n",
    "    recall = recall_score(y_test_mean, preds)\n",
    "\n",
    "    print(f\"Test F1-Score: {f1}\")\n",
    "    print(f\"Test Precision: {precision}\")\n",
    "    print(f\"Test Recall: {recall}\")\n",
    "    print(\"\\n\\n\")\n",
    "    results_dict[model_name] = (f1, precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9bf30b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Nearest Neighbor</th>\n",
       "      <td>0.474041</td>\n",
       "      <td>0.530303</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.468421</td>\n",
       "      <td>0.659259</td>\n",
       "      <td>0.363265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.462810</td>\n",
       "      <td>0.468619</td>\n",
       "      <td>0.457143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.460784</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.383673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.757282</td>\n",
       "      <td>0.318367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ada Boost</th>\n",
       "      <td>0.284884</td>\n",
       "      <td>0.494949</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  F1-Score  Precision    Recall\n",
       "Nearest Neighbor  0.474041   0.530303  0.428571\n",
       "Random Forest     0.468421   0.659259  0.363265\n",
       "Decision Tree     0.462810   0.468619  0.457143\n",
       "Bagging           0.460784   0.576687  0.383673\n",
       "SVM               0.448276   0.757282  0.318367\n",
       "Ada Boost         0.284884   0.494949  0.200000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = (pd.DataFrame.from_dict(results_dict, orient=\"index\", columns=[\"F1-Score\", \"Precision\", \"Recall\"])\n",
    "             .sort_values(by=\"F1-Score\", ascending=False))\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3da263",
   "metadata": {},
   "source": [
    "For the sake of easy interpretation, the following models shall be examined further by applying hyper-parameter optimization on them: \n",
    "1. Decision Tree\n",
    "2. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f869a95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
